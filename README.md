# oc-serve
OC-Serve is an open-architecture, enterprise-grade model serving framework for deploying and managing AI models (LLMs, LVMs, STT, TTS) easily, efficiently, and scalably in production. Supporting multiple serving engines (vLLM, SGLang, TensorRT-LLM, etc), offering cloud-native deployment, OpenAI-compatible APIs, and robust orchestration.
